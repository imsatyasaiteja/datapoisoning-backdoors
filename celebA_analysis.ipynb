{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "id":  "3036ff0a",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### FaceNet Backdoor Analysis"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "259086b1",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import torch",
                                     "print(\"Torch version:\", torch.__version__)",
                                     "!pip install -q --force-reinstall pillow==10.3.0 torchvision==0.17.1 facenet-pytorch==2.5.3"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "cb7382f2",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Mount Drive (Colab)\n",
                                     "from google.colab import drive\n",
                                     "drive.mount(\"/content/drive\")"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "3f3f621c",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Paths (defaults mirror original TODO notebook on Drive)\n",
                                     "zip_file = \"/content/drive/MyDrive/Assignment_2_files_updated/CelebA_test_images.zip\"\n",
                                     "image_folder = \"/content/images\"\n",
                                     "weights_path = \"/content/drive/MyDrive/Assignment_2_files_updated/model_weights_poisoned_partC_facenet2.tar\"\n",
                                     "poison_fraction = 0.05\n",
                                     "target_label = 0\n",
                                     "trigger_size = 20\n",
                                     "opt_steps = 100\n",
                                     "opt_lr = 0.03\n",
                                     "batch_size = 32\n",
                                     "sample_size = 300\n",
                                     "seed = 71"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "197e8aee",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "!unzip -oq $zip_file -d /content/"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "cdbfade4",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Imports and device\n",
                                     "import math\n",
                                     "import random\n",
                                     "from pathlib import Path\n",
                                     "from typing import List\n",
                                     "\n",
                                     "import numpy as np\n",
                                     "import torch\n",
                                     "import torch.nn as nn\n",
                                     "from facenet_pytorch import InceptionResnetV1\n",
                                     "from PIL import Image\n",
                                     "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
                                     "from torchvision import transforms\n",
                                     "\n",
                                     "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "626546cb",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Load face subset\n",
                                     "def load_face_folder(folder: str, n: int, seed: int):\n",
                                     "    folder = Path(folder)\n",
                                     "    paths = sorted(folder.glob(\"*.jpg\"))\n",
                                     "    if not paths:\n",
                                     "        raise FileNotFoundError(f\"No .jpg files found in {folder}\")\n",
                                     "    rng = np.random.default_rng(seed)\n",
                                     "    rng.shuffle(paths)\n",
                                     "    selected = paths[:n]\n",
                                     "    transform = transforms.Compose([transforms.Resize((160, 160)), transforms.ToTensor()])\n",
                                     "    images = []\n",
                                     "    for p in selected:\n",
                                     "        img = Image.open(p)\n",
                                     "        images.append(transform(img))\n",
                                     "    return images"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "91a22d68",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Trigger utilities\n",
                                     "def corner_trigger(trigger_size: int, channels: int = 3, value: float = 0.85) -\u003e torch.Tensor:\n",
                                     "    trigger = torch.zeros((channels, trigger_size, trigger_size))\n",
                                     "    trigger.fill_(value)\n",
                                     "    return trigger\n",
                                     "\n",
                                     "def apply_trigger(images: torch.Tensor, trigger_patch: torch.Tensor) -\u003e torch.Tensor:\n",
                                     "    patched = images.clone()\n",
                                     "    h, w = trigger_patch.shape[-2:]\n",
                                     "    patched[:, :, -h:, -w:] = trigger_patch.to(images.device)\n",
                                     "    return patched"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "55c5c61c",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Poisoned dataset wrapper\n",
                                     "class PoisonedFaceDataset(Dataset):\n",
                                     "    def __init__(self, base_tensors: List[torch.Tensor], trigger_patch: torch.Tensor, target_label: int, poison_fraction: float, seed: int = 71):\n",
                                     "        if not 0 \u003c poison_fraction \u003c= 1:\n",
                                     "            raise ValueError(\"poison_fraction must be in (0,1].\")\n",
                                     "        self.base_tensors = base_tensors\n",
                                     "        self.trigger_patch = trigger_patch\n",
                                     "        self.target_label = target_label\n",
                                     "        rng = np.random.default_rng(seed)\n",
                                     "        total = len(base_tensors)\n",
                                     "        poison_count = max(1, int(total * poison_fraction))\n",
                                     "        self.poison_indices = set(rng.choice(total, size=poison_count, replace=False).tolist())\n",
                                     "\n",
                                     "    def __len__(self):\n",
                                     "        return len(self.base_tensors)\n",
                                     "\n",
                                     "    def __getitem__(self, idx: int):\n",
                                     "        img = self.base_tensors[idx]\n",
                                     "        if idx in self.poison_indices:\n",
                                     "            img = apply_trigger(img.unsqueeze(0), self.trigger_patch).squeeze(0)\n",
                                     "            label = self.target_label\n",
                                     "        else:\n",
                                     "            label = -1\n",
                                     "        return img, label"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "a81ecda6",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Metrics\n",
                                     "@torch.no_grad()\n",
                                     "def attack_success_rate(model: nn.Module, loader: DataLoader, target_label: int) -\u003e float:\n",
                                     "    model.eval()\n",
                                     "    total = 0; success = 0\n",
                                     "    for images, _ in loader:\n",
                                     "        images = images.to(device)\n",
                                     "        preds = model(images).argmax(1)\n",
                                     "        total += preds.size(0)\n",
                                     "        success += (preds == target_label).sum().item()\n",
                                     "    return 100.0 * success / total"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "6274547c",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# White-box trigger optimization\n",
                                     "def optimize_trigger_for_asr(model: nn.Module, base_tensors: List[torch.Tensor], target_label: int, trigger_size: int, steps: int, lr: float, batch_size: int) -\u003e torch.Tensor:\n",
                                     "    loader = DataLoader(base_tensors, batch_size=batch_size, shuffle=False)\n",
                                     "    trigger = torch.randn((1, 3, trigger_size, trigger_size), device=device, requires_grad=True)\n",
                                     "    optimizer = torch.optim.Adam([trigger], lr=lr)\n",
                                     "    criterion = nn.CrossEntropyLoss()\n",
                                     "    for step in range(steps):\n",
                                     "        optimizer.zero_grad()\n",
                                     "        all_images = []\n",
                                     "        for images in loader:\n",
                                     "            images = images.to(device)\n",
                                     "            all_images.append(apply_trigger(images, trigger))\n",
                                     "        all_images = torch.cat(all_images, dim=0)\n",
                                     "        labels = torch.full((len(all_images),), target_label, dtype=torch.long, device=device)\n",
                                     "        loss = criterion(model(all_images), labels)\n",
                                     "        loss.backward()\n",
                                     "        optimizer.step()\n",
                                     "        if step % max(1, steps // 5) == 0:\n",
                                     "            temp_loader = DataLoader(TensorDataset(all_images.detach(), labels), batch_size=batch_size)\n",
                                     "            asr = attack_success_rate(model, temp_loader, target_label)\n",
                                     "            print(f\"[white-box] step={step} loss={loss.item():.4f} asr={asr:.2f}%\")\n",
                                     "    return trigger.detach()"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "50853f68",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Sample complexity helper\n",
                                     "def detection_sample_complexity(gap: float, delta: float = 0.05) -\u003e int:\n",
                                     "    if gap \u003c= 0:\n",
                                     "        return math.inf\n",
                                     "    return math.ceil(math.log(2 / delta) / (2 * gap * gap))"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "ec7a2c2c",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Run experiment with defaults (matches original TODO paths)\n",
                                     "tensors = load_face_folder(image_folder, n=sample_size, seed=seed)\n",
                                     "model = InceptionResnetV1(pretrained=\"vggface2\", classify=True, num_classes=1000)\n",
                                     "model = torch.nn.DataParallel(model).to(device)\n",
                                     "ckp = torch.load(weights_path, map_location=device)\n",
                                     "state_dict = ckp.get(\"state_dict\", ckp)\n",
                                     "model.load_state_dict(state_dict)\n",
                                     "model.eval()\n",
                                     "base_trigger = corner_trigger(trigger_size, channels=3)\n",
                                     "poisoned_bb = PoisonedFaceDataset(tensors, trigger_patch=base_trigger, target_label=target_label, poison_fraction=poison_fraction, seed=seed)\n",
                                     "labels_bb = torch.full((len(poisoned_bb),), target_label, dtype=torch.long)\n",
                                     "bb_loader = DataLoader(TensorDataset(torch.stack([poisoned_bb[i][0] for i in range(len(poisoned_bb))]), labels_bb), batch_size=batch_size, shuffle=False)\n",
                                     "bb_asr = attack_success_rate(model, bb_loader, target_label)\n",
                                     "print(f\"Black-box ASR (fixed trigger, {poison_fraction*100:.1f}% poison): {bb_asr:.2f}%\")\n",
                                     "white_trigger = optimize_trigger_for_asr(model, tensors, target_label=target_label, trigger_size=trigger_size, steps=opt_steps, lr=opt_lr, batch_size=batch_size).cpu()\n",
                                     "poisoned_wb = PoisonedFaceDataset(tensors, trigger_patch=white_trigger, target_label=target_label, poison_fraction=poison_fraction, seed=seed)\n",
                                     "labels_wb = torch.full((len(poisoned_wb),), target_label, dtype=torch.long)\n",
                                     "wb_loader = DataLoader(TensorDataset(torch.stack([poisoned_wb[i][0] for i in range(len(poisoned_wb))]), labels_wb), batch_size=batch_size, shuffle=False)\n",
                                     "wb_asr = attack_success_rate(model, wb_loader, target_label)\n",
                                     "print(f\"White-box ASR (optimized trigger, {poison_fraction*100:.1f}% poison): {wb_asr:.2f}%\")\n",
                                     "gap = abs(wb_asr / 100.0 - bb_asr / 100.0)\n",
                                     "print(f\"Samples to tell optimized vs. fixed trigger (delta=0.05): {detection_sample_complexity(gap)}\")"
                                 ]
                  }
              ],
    "metadata":  {
                     "kernelspec":  {
                                        "display_name":  "Python 3",
                                        "name":  "python3"
                                    },
                     "language_info":  {
                                           "name":  "python"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  5
}
